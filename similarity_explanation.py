#!/usr/bin/env python3
"""
ç‚¹ç§¯ç›¸ä¼¼åº¦çš„æ•°å­¦åŸç†æ¼”ç¤º
è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆ QÂ·K^T èƒ½å¤Ÿè®¡ç®—ç›¸ä¼¼åº¦
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from mpl_toolkits.mplot3d import Axes3D

def demonstrate_dot_product_similarity():
    """æ¼”ç¤ºç‚¹ç§¯ä½œä¸ºç›¸ä¼¼åº¦åº¦é‡çš„åŸç†"""
    print("=" * 70)
    print("ç‚¹ç§¯ç›¸ä¼¼åº¦çš„æ•°å­¦åŸç†æ¼”ç¤º")
    print("=" * 70)
    
    # 1. åŸºç¡€å‡ ä½•åŸç†
    print("\n1. å‡ ä½•åŸç†ï¼šç‚¹ç§¯ä¸å‘é‡å¤¹è§’")
    print("-" * 40)
    
    # åˆ›å»ºç¤ºä¾‹å‘é‡
    a = np.array([3, 4])  # å‘é‡a
    b1 = np.array([6, 8])  # å‘é‡b1 (ä¸aåŒæ–¹å‘)
    b2 = np.array([4, -3])  # å‘é‡b2 (ä¸aå‚ç›´)
    b3 = np.array([-3, -4])  # å‘é‡b3 (ä¸aåæ–¹å‘)
    
    # è®¡ç®—ç‚¹ç§¯
    dot_a_b1 = np.dot(a, b1)
    dot_a_b2 = np.dot(a, b2)
    dot_a_b3 = np.dot(a, b3)
    
    # è®¡ç®—å¤¹è§’
    def angle_between_vectors(v1, v2):
        cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
        # é˜²æ­¢æ•°å€¼è¯¯å·®
        cos_angle = np.clip(cos_angle, -1.0, 1.0)
        return np.arccos(cos_angle) * 180 / np.pi
    
    angle_a_b1 = angle_between_vectors(a, b1)
    angle_a_b2 = angle_between_vectors(a, b2)
    angle_a_b3 = angle_between_vectors(a, b3)
    
    print(f"å‘é‡a = {a}")
    print(f"å‘é‡b1 = {b1} (åŒæ–¹å‘)")
    print(f"  ç‚¹ç§¯: {dot_a_b1:.2f}, å¤¹è§’: {angle_a_b1:.1f}Â°")
    print(f"å‘é‡b2 = {b2} (å‚ç›´)")
    print(f"  ç‚¹ç§¯: {dot_a_b2:.2f}, å¤¹è§’: {angle_a_b2:.1f}Â°")
    print(f"å‘é‡b3 = {b3} (åæ–¹å‘)")
    print(f"  ç‚¹ç§¯: {dot_a_b3:.2f}, å¤¹è§’: {angle_a_b3:.1f}Â°")
    
    # 2. æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„è¯­ä¹‰ç¤ºä¾‹
    print("\n2. æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„è¯­ä¹‰ç›¸ä¼¼åº¦")
    print("-" * 40)
    
    # æ¨¡æ‹Ÿè¯å‘é‡ (ç®€åŒ–ä¸º2Dä¾¿äºç†è§£)
    # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªç®€å•çš„è¯­ä¹‰ç©ºé—´ï¼š[è¯­æ³•ç»´åº¦, è¯­ä¹‰ç»´åº¦]
    
    word_vectors = {
        "cat": np.array([0.8, 0.9]),      # åè¯ï¼ŒåŠ¨ç‰©
        "dog": np.array([0.7, 0.8]),      # åè¯ï¼ŒåŠ¨ç‰©  
        "run": np.array([-0.6, 0.3]),     # åŠ¨è¯ï¼ŒåŠ¨ä½œ
        "quickly": np.array([-0.3, 0.2]), # å‰¯è¯ï¼Œä¿®é¥°
        "the": np.array([0.1, 0.0]),      # å† è¯ï¼ŒåŠŸèƒ½è¯
    }
    
    # å‡è®¾å½“å‰Queryæ˜¯"cat"ï¼Œæˆ‘ä»¬è®¡ç®—å®ƒä¸æ‰€æœ‰Keyçš„ç›¸ä¼¼åº¦
    query = word_vectors["cat"]
    
    print(f"Query (cat): {query}")
    print("\nå„ä¸ªKeyçš„ç›¸ä¼¼åº¦:")
    
    similarities = {}
    for word, key_vector in word_vectors.items():
        similarity = np.dot(query, key_vector)
        similarities[word] = similarity
        cosine_sim = similarity / (np.linalg.norm(query) * np.linalg.norm(key_vector))
        print(f"  {word:8}: ç‚¹ç§¯={similarity:.3f}, ä½™å¼¦ç›¸ä¼¼åº¦={cosine_sim:.3f}")
    
    # æ’åºæ˜¾ç¤ºæœ€ç›¸ä¼¼çš„è¯
    sorted_words = sorted(similarities.items(), key=lambda x: x[1], reverse=True)
    print(f"\nç›¸ä¼¼åº¦æ’åº: {[word for word, _ in sorted_words]}")
    
    return a, b1, b2, b3, word_vectors, similarities

def demonstrate_attention_calculation():
    """æ¼”ç¤ºæ³¨æ„åŠ›æœºåˆ¶ä¸­çš„å®Œæ•´è®¡ç®—è¿‡ç¨‹"""
    print("\n3. æ³¨æ„åŠ›æœºåˆ¶å®Œæ•´è®¡ç®—ç¤ºä¾‹")
    print("-" * 40)
    
    # åˆ›å»ºç¤ºä¾‹å¥å­çš„å‘é‡è¡¨ç¤º
    # å¥å­: "The cat sits on mat"
    # ç®€åŒ–ä¸º3ç»´å‘é‡: [ä½ç½®ä¿¡æ¯, è¯­æ³•ä¿¡æ¯, è¯­ä¹‰ä¿¡æ¯]
    
    sentence_vectors = {
        "The": np.array([1.0, 0.9, 0.1]),    # ä½ç½®1ï¼Œå† è¯ï¼Œä½è¯­ä¹‰
        "cat": np.array([2.0, 0.8, 0.9]),    # ä½ç½®2ï¼Œåè¯ï¼Œé«˜è¯­ä¹‰
        "sits": np.array([3.0, -0.7, 0.6]),  # ä½ç½®3ï¼ŒåŠ¨è¯ï¼Œä¸­è¯­ä¹‰  
        "on": np.array([4.0, -0.2, 0.3]),    # ä½ç½®4ï¼Œä»‹è¯ï¼Œä½è¯­ä¹‰
        "mat": np.array([5.0, 0.7, 0.8]),    # ä½ç½®5ï¼Œåè¯ï¼Œé«˜è¯­ä¹‰
    }
    
    # æ„é€ Query, Key, ValueçŸ©é˜µ
    words = list(sentence_vectors.keys())
    vectors = np.array(list(sentence_vectors.values()))
    
    # å‡è®¾Query, Key, Valueéƒ½æ˜¯ç›¸åŒçš„ (è‡ªæ³¨æ„åŠ›)
    Q = vectors  # Shape: (5, 3)
    K = vectors  # Shape: (5, 3)  
    V = vectors  # Shape: (5, 3)
    
    print(f"å¥å­: {' '.join(words)}")
    print(f"å‘é‡ç»´åº¦: {vectors.shape}")
    
    # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ
    scores = Q @ K.T  # Shape: (5, 5)
    
    print(f"\næ³¨æ„åŠ›åˆ†æ•°çŸ©é˜µ (Q @ K^T):")
    print("       ", "  ".join(f"{w:>6}" for w in words))
    for i, word in enumerate(words):
        row_scores = "  ".join(f"{scores[i,j]:6.2f}" for j in range(len(words)))
        print(f"{word:>6}: {row_scores}")
    
    # åº”ç”¨softmax
    def softmax(x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # æ•°å€¼ç¨³å®šæ€§
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    attention_weights = softmax(scores)
    
    print(f"\næ³¨æ„åŠ›æƒé‡çŸ©é˜µ (softmaxå):")
    print("       ", "  ".join(f"{w:>6}" for w in words))
    for i, word in enumerate(words):
        row_weights = "  ".join(f"{attention_weights[i,j]:6.3f}" for j in range(len(words)))
        print(f"{word:>6}: {row_weights}")
        # éªŒè¯å½’ä¸€åŒ–
        row_sum = np.sum(attention_weights[i, :])
        print(f"        (è¡Œå’Œ: {row_sum:.3f})")
    
    # åˆ†ææ³¨æ„åŠ›æ¨¡å¼
    print(f"\næ³¨æ„åŠ›æ¨¡å¼åˆ†æ:")
    for i, query_word in enumerate(words):
        max_attention_idx = np.argmax(attention_weights[i, :])
        max_attention_word = words[max_attention_idx]
        max_weight = attention_weights[i, max_attention_idx]
        
        print(f"  {query_word} æœ€å…³æ³¨ {max_attention_word} (æƒé‡: {max_weight:.3f})")
        
        # æ‰¾å‡ºå‰3ä¸ªå…³æ³¨çš„è¯
        top3_indices = np.argsort(attention_weights[i, :])[-3:][::-1]
        top3_words = [(words[idx], attention_weights[i, idx]) for idx in top3_indices]
        top3_str = ", ".join([f"{w}({w:.3f})" for w, w in top3_words])
        print(f"    å‰3å…³æ³¨: {top3_str}")
    
    return Q, K, V, scores, attention_weights

def visualize_similarity_concepts():
    """å¯è§†åŒ–ç›¸ä¼¼åº¦æ¦‚å¿µ"""
    print("\n4. å¯è§†åŒ–ç›¸ä¼¼åº¦æ¦‚å¿µ")
    print("-" * 40)
    
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. å‘é‡å¤¹è§’å¯è§†åŒ–
    ax1.set_title("å‘é‡å¤¹è§’ä¸ç‚¹ç§¯çš„å…³ç³»", fontsize=12, fontweight='bold')
    
    # åˆ›å»ºå‘é‡
    origin = [0, 0]
    a = [3, 4]
    b1 = [6, 8]  # åŒæ–¹å‘
    b2 = [4, -3]  # å‚ç›´
    b3 = [-2, -2.67]  # åæ–¹å‘
    
    # ç»˜åˆ¶å‘é‡
    ax1.quiver(*origin, *a, angles='xy', scale_units='xy', scale=1, color='red', width=0.005, label='å‘é‡a')
    ax1.quiver(*origin, *b1, angles='xy', scale_units='xy', scale=1, color='green', width=0.005, label='å‘é‡b1(åŒå‘)')
    ax1.quiver(*origin, *b2, angles='xy', scale_units='xy', scale=1, color='blue', width=0.005, label='å‘é‡b2(å‚ç›´)')
    ax1.quiver(*origin, *b3, angles='xy', scale_units='xy', scale=1, color='orange', width=0.005, label='å‘é‡b3(åå‘)')
    
    # æ·»åŠ ç‚¹ç§¯å€¼
    dot_ab1 = np.dot(a, b1)
    dot_ab2 = np.dot(a, b2)
    dot_ab3 = np.dot(a, b3)
    
    ax1.text(6.5, 8.5, f'aÂ·b1={dot_ab1:.1f}', fontsize=10, color='green')
    ax1.text(4.5, -2.5, f'aÂ·b2={dot_ab2:.1f}', fontsize=10, color='blue')
    ax1.text(-1.5, -2, f'aÂ·b3={dot_ab3:.1f}', fontsize=10, color='orange')
    
    ax1.set_xlim(-8, 10)
    ax1.set_ylim(-8, 10)
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    ax1.set_aspect('equal')
    
    # 2. å¤¹è§’vsç‚¹ç§¯å…³ç³»å›¾
    angles = np.linspace(0, 180, 100)
    cosines = np.cos(np.radians(angles))
    
    ax2.plot(angles, cosines, 'b-', linewidth=2)
    ax2.set_title("cos(Î¸) éšå¤¹è§’å˜åŒ–", fontsize=12, fontweight='bold')
    ax2.set_xlabel("å¤¹è§’ (åº¦)")
    ax2.set_ylabel("cos(Î¸)")
    ax2.grid(True, alpha=0.3)
    
    # æ ‡è®°å…³é”®ç‚¹
    key_angles = [0, 90, 180]
    key_cosines = [1, 0, -1]
    key_labels = ['å®Œå…¨ç›¸ä¼¼', 'æ— å…³', 'å®Œå…¨ç›¸å']
    
    for angle, cosine, label in zip(key_angles, key_cosines, key_labels):
        ax2.plot(angle, cosine, 'ro', markersize=8)
        ax2.annotate(label, (angle, cosine), xytext=(10, 10), 
                    textcoords='offset points', fontsize=10)
    
    # 3. æ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾ç¤ºä¾‹
    # åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ³¨æ„åŠ›çŸ©é˜µ
    words = ["The", "cat", "sits", "on", "mat"]
    attention_matrix = np.array([
        [0.7, 0.1, 0.1, 0.05, 0.05],  # The
        [0.1, 0.6, 0.2, 0.05, 0.05],  # cat  
        [0.05, 0.3, 0.5, 0.1, 0.05],  # sits
        [0.05, 0.1, 0.2, 0.4, 0.25],  # on
        [0.05, 0.2, 0.1, 0.15, 0.5],  # mat
    ])
    
    sns.heatmap(attention_matrix, annot=True, fmt='.2f', 
                xticklabels=words, yticklabels=words,
                cmap='Blues', ax=ax3, cbar_kws={'label': 'Attention Weight'})
    ax3.set_title("æ³¨æ„åŠ›æƒé‡çŸ©é˜µç¤ºä¾‹", fontsize=12, fontweight='bold')
    ax3.set_xlabel("Key (è¢«å…³æ³¨çš„è¯)")
    ax3.set_ylabel("Query (æŸ¥è¯¢è¯)")
    
    # 4. ç›¸ä¼¼åº¦åˆ†å¸ƒ
    # ç”Ÿæˆéšæœºå‘é‡å¹¶è®¡ç®—ç›¸ä¼¼åº¦åˆ†å¸ƒ
    np.random.seed(42)
    n_samples = 1000
    
    # ç”Ÿæˆéšæœºå•ä½å‘é‡
    vectors = np.random.randn(n_samples, 2)
    vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
    
    # é€‰æ‹©ä¸€ä¸ªå›ºå®šçš„æŸ¥è¯¢å‘é‡
    query_vec = np.array([1, 0])
    
    # è®¡ç®—æ‰€æœ‰å‘é‡ä¸æŸ¥è¯¢å‘é‡çš„ç‚¹ç§¯(ä½™å¼¦ç›¸ä¼¼åº¦)
    similarities = vectors @ query_vec
    
    ax4.hist(similarities, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
    ax4.set_title("éšæœºå‘é‡ç›¸ä¼¼åº¦åˆ†å¸ƒ", fontsize=12, fontweight='bold')
    ax4.set_xlabel("ç›¸ä¼¼åº¦ (ç‚¹ç§¯)")
    ax4.set_ylabel("é¢‘ç‡")
    ax4.axvline(0, color='red', linestyle='--', label='æ— å…³(ç›¸ä¼¼åº¦=0)')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('similarity_visualization.png', dpi=300, bbox_inches='tight')
    print("å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜ä¸º 'similarity_visualization.png'")
    
    return fig

def mathematical_intuition():
    """æä¾›æ•°å­¦ç›´è§‰çš„è¯¦ç»†è§£é‡Š"""
    print("\n5. æ•°å­¦ç›´è§‰ï¼šä¸ºä»€ä¹ˆç‚¹ç§¯è¡¡é‡ç›¸ä¼¼åº¦ï¼Ÿ")
    print("-" * 50)
    
    print("""
ğŸ”¹ **å‡ ä½•è§£é‡Š**ï¼š
   ç‚¹ç§¯ aÂ·b = |a||b|cos(Î¸) ä¸­çš„ cos(Î¸) é¡¹ç›´æ¥åæ˜ æ–¹å‘ç›¸ä¼¼æ€§
   - Î¸ = 0Â°  â†’ cos(Î¸) = 1  â†’ å®Œå…¨ç›¸åŒæ–¹å‘ â†’ é«˜ç›¸ä¼¼åº¦
   - Î¸ = 90Â° â†’ cos(Î¸) = 0  â†’ æ­£äº¤æ–¹å‘     â†’ æ— ç›¸å…³æ€§  
   - Î¸ = 180Â°â†’ cos(Î¸) = -1 â†’ å®Œå…¨ç›¸åæ–¹å‘ â†’ è´Ÿç›¸ä¼¼åº¦

ğŸ”¹ **ä»£æ•°è§£é‡Š**ï¼š
   å¯¹äºå‘é‡ a = [aâ‚, aâ‚‚, ..., aâ‚™], b = [bâ‚, bâ‚‚, ..., bâ‚™]
   ç‚¹ç§¯ aÂ·b = aâ‚bâ‚ + aâ‚‚bâ‚‚ + ... + aâ‚™bâ‚™
   
   å½“å¯¹åº”ç»´åº¦åŒå·ä¸”æ•°å€¼å¤§æ—¶ï¼Œä¹˜ç§¯ä¸ºæ­£ä¸”å¤§ â†’ é«˜ç›¸ä¼¼åº¦
   å½“å¯¹åº”ç»´åº¦å¼‚å·æ—¶ï¼Œä¹˜ç§¯ä¸ºè´Ÿ â†’ è´Ÿç›¸ä¼¼åº¦
   å½“å¯¹åº”ç»´åº¦ä¹˜ç§¯ç›¸äº’æŠµæ¶ˆæ—¶ â†’ ä½ç›¸ä¼¼åº¦

ğŸ”¹ **ä¿¡æ¯è®ºè§£é‡Š**ï¼š
   ç‚¹ç§¯å¯ä»¥çœ‹ä½œæ˜¯ä¸¤ä¸ªå‘é‡åœ¨å½¼æ­¤æ–¹å‘ä¸Šçš„"æŠ•å½±å¼ºåº¦"
   - æŠ•å½±å¤§ â†’ å‘é‡åœ¨è¯¥æ–¹å‘ä¸Šæœ‰å¼ºä¿¡å· â†’ é«˜ç›¸å…³æ€§
   - æŠ•å½±å° â†’ å‘é‡åœ¨è¯¥æ–¹å‘ä¸Šä¿¡å·å¼± â†’ ä½ç›¸å…³æ€§

ğŸ”¹ **æœºå™¨å­¦ä¹ è§£é‡Š**ï¼š
   åœ¨é«˜ç»´è¯­ä¹‰ç©ºé—´ä¸­ï¼š
   - ç›¸ä¼¼æ¦‚å¿µçš„å‘é‡è¶‹å‘äºæŒ‡å‘ç›¸ä¼¼æ–¹å‘
   - ç‚¹ç§¯è‡ªç„¶åœ°æ•è·äº†è¿™ç§æ–¹å‘ç›¸ä¼¼æ€§
   - è¿™æ­£æ˜¯æˆ‘ä»¬åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­æƒ³è¦çš„"è¯­ä¹‰åŒ¹é…"
    
ğŸ”¹ **ä¸ºä»€ä¹ˆä¸ç”¨å…¶ä»–è·ç¦»ï¼Ÿ**
   - æ¬§å‡ é‡Œå¾—è·ç¦» ||a-b||ï¼šå…³æ³¨æ•°å€¼å·®å¼‚ï¼Œä¸è€ƒè™‘æ–¹å‘
   - æ›¼å“ˆé¡¿è·ç¦»ï¼šåŒæ ·å…³æ³¨æ•°å€¼å·®å¼‚
   - ç‚¹ç§¯ï¼šå…³æ³¨æ–¹å‘ç›¸ä¼¼æ€§ï¼Œè¿™æ›´ç¬¦åˆè¯­ä¹‰åŒ¹é…çš„éœ€æ±‚
   
ğŸ”¹ **åœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„åº”ç”¨**ï¼š
   QueryÂ·Key å¤§ â†’ Queryæ‰€éœ€ä¿¡æ¯ä¸Keyæä¾›ä¿¡æ¯åŒ¹é…åº¦é«˜
                â†’ åº”è¯¥ç»™è¯¥Keyå¯¹åº”çš„Valueæ›´é«˜æƒé‡
                â†’ è¿™æ­£æ˜¯æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒæ€æƒ³ï¼
""")

if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    demonstrate_dot_product_similarity()
    demonstrate_attention_calculation()
    visualize_similarity_concepts()
    mathematical_intuition()
    
    print("\n" + "=" * 70)
    print("æ€»ç»“ï¼šç‚¹ç§¯ä½œä¸ºç›¸ä¼¼åº¦åº¦é‡çš„åŸç†")
    print("=" * 70)
    print("""
ç‚¹ç§¯èƒ½å¤Ÿè®¡ç®—ç›¸ä¼¼åº¦çš„æ ¸å¿ƒåŸå› ï¼š

1. **å‡ ä½•ç›´è§‰**ï¼šç‚¹ç§¯åŒ…å«cos(Î¸)é¡¹ï¼Œç›´æ¥åæ˜ å‘é‡æ–¹å‘ç›¸ä¼¼æ€§
2. **ä»£æ•°æ€§è´¨**ï¼šå¯¹åº”ç»´åº¦çš„ä¹˜ç§¯å’Œï¼ŒåŒå‘è´¡çŒ®ä¸ºæ­£ï¼Œå¼‚å‘ä¸ºè´Ÿ
3. **è¯­ä¹‰åŒ¹é…**ï¼šåœ¨è¯­ä¹‰ç©ºé—´ä¸­ï¼Œç›¸ä¼¼æ¦‚å¿µå‘é‡æ–¹å‘ç›¸è¿‘
4. **è®¡ç®—æ•ˆç‡**ï¼šçº¿æ€§è¿ç®—ï¼Œé€‚åˆå¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—
5. **å¯è§£é‡Šæ€§**ï¼šç»“æœç›´è§‚ï¼Œå¤§å€¼è¡¨ç¤ºé«˜ç›¸ä¼¼åº¦

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ³¨æ„åŠ›æœºåˆ¶é€‰æ‹© QÂ·K^T ä½œä¸ºç›¸ä¼¼åº¦è®¡ç®—çš„åŸå› ï¼
""") 